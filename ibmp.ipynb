{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr \n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import string\n",
    "from pathlib import *\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import glob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import pyttsx3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recorder(): \n",
    "    r = sr.Recognizer()                 # initialize recognizer\n",
    "    with sr.Microphone() as source:     # mention source it will be either Microphone or audio files.\n",
    "        print(\"Speak your query :\")\n",
    "        audio = r.listen(source)        # listen to the source\n",
    "        try:\n",
    "            speech = r.recognize_google(audio)    # use recognizer to convert our audio into text part.\n",
    "            \n",
    "            print(\"You said : {}\".format(speech))\n",
    "        except:\n",
    "            print(\"Sorry could not recognize your voice\")\n",
    "    return(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanspeech(speech):\n",
    "    \n",
    "    speech=speech.lower() #lowercase\n",
    "    \n",
    "    punct = string.punctuation #remve punctuations\n",
    "    trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "    speech=speech.translate(trantab)\n",
    "    \n",
    "    stopwords_list = stopwords.words('english') #remove stopwords\n",
    "    whitelist=['during','before','after','above','below','up','down','no','not']\n",
    "    words = speech.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "    speech=\" \".join(clean_words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list=word_tokenize(speech)\n",
    "    speech= [lemmatizer.lemmatize(w) for w in word_list]\n",
    "    \n",
    "    return (speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandocument(data1):\n",
    "    \n",
    "    data1[0]=data1[0].str.lower()\n",
    "    punct = string.punctuation #remve punctuations\n",
    "    trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "    data1[1]=data1[0].str.translate(trantab) \n",
    "    def replace(word):\n",
    "        return(word.replace('\\n',' '))\n",
    "    data1[1]=data1.apply(lambda x:replace(x[1]),axis=1)\n",
    "    stop = stopwords.words('english')\n",
    "    data1[1] = data1[1].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    w_tokenizer = WhitespaceTokenizer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize_text(text):\n",
    "        return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "    data1[1] = data1[1].apply(lemmatize_text)\n",
    "    \n",
    "    return (data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpdf():\n",
    "    data=pd.DataFrame()\n",
    "    dir_path = Path('F:/NOTES/sem7- bda ibm/cases')\n",
    "    pdf_files = dir_path.glob('*.pdf')\n",
    "    i=0\n",
    "    for files in pdf_files:\n",
    "        pdfFileObj = open(files,'rb')\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        num_pages = pdfReader.numPages\n",
    "        count = 0\n",
    "        data.loc[i,0] = \"\"\n",
    "        while count < num_pages:\n",
    "            pageObj = pdfReader.getPage(count)\n",
    "            count +=1\n",
    "            data.loc[i,0] += pageObj.extractText()\n",
    "            #This if statement exists to check if the above library returned #words. It's done because PyPDF2 cannot read scanned files.\n",
    "            if data.loc[i,0] != \"\":\n",
    "               data.loc[i,0] = data.loc[i,0]\n",
    "            #If the above returns as False, we run the OCR library textract to #convert scanned/image based PDF files into text\n",
    "            else:\n",
    "               data.loc[i,0] = textract.process(fileurl, method='tesseract', language='eng')        \n",
    "        i=i+1\n",
    "        \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(output):\n",
    "    for k in range(len(output)):\n",
    "        engine = pyttsx3.init() \n",
    "        engine.say(output.loc[k,0]) \n",
    "        engine.runAndWait() \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searching_query(speech,data2):\n",
    "    data3=pd.DataFrame()\n",
    "    querylen=len(speech)\n",
    "    i=j=t=0\n",
    "    for j in range(len(data2)):\n",
    "        for i in range(querylen):\n",
    "            if (speech[i] in  data2['keywords'].loc[j]):\n",
    "                data3.loc[t,0]=data2['data'].loc[j]\n",
    "        t=t+1\n",
    "    return (data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak your query :\n",
      "You said : Supreme India\n",
      "['supreme', 'india']\n"
     ]
    }
   ],
   "source": [
    "query=recorder()\n",
    "speech=cleanspeech(query)\n",
    "print(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-reportable\\nin the supreme court of india\\...</td>\n",
       "      <td>[non, reportable, supreme, court, india, crimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1\\n \\n \\nreportable\\n \\n \\n \\n                ...</td>\n",
       "      <td>[1, reportable, supreme, court, india, civil, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  non-reportable\\nin the supreme court of india\\...   \n",
       "1  1\\n \\n \\nreportable\\n \\n \\n \\n                ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [non, reportable, supreme, court, india, crimi...  \n",
       "1  [1, reportable, supreme, court, india, civil, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.DataFrame()\n",
    "data1=loadpdf()\n",
    "data2=cleandocument(data1)\n",
    "data2=data2.rename(columns={0: \"data\", 1: \"keywords\"})  \n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>non-reportable\\nin the supreme court of india\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1\\n \\n \\nreportable\\n \\n \\n \\n                ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                  0\n",
       "0      0  non-reportable\\nin the supreme court of india\\...\n",
       "1      1  1\\n \\n \\nreportable\\n \\n \\n \\n                ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=searching_query(speech,data2)\n",
    "output.reset_index(inplace=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_speech(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
